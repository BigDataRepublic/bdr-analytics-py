{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please provide the folder containing the soi.dat and recruit.dat datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafolder = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me check if you provided the correct folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "has_soi = sum([name.endswith(\"soi.dat\") for name in os.listdir(datafolder)])\n",
    "has_recruit = sum([name.endswith(\"recruit.dat\") for name in os.listdir(datafolder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are ready to go\n"
     ]
    }
   ],
   "source": [
    "if (has_soi and has_recruit):\n",
    "    print 'You are ready to go'\n",
    "else:\n",
    "    print 'Found files:'\n",
    "    print os.listdir(datafolder)\n",
    "    print ''\n",
    "if not has_soi:\n",
    "    print 'You are missing soi.dat'\n",
    "if not has_recruit:\n",
    "    print 'You are missing recruit.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The following blocks setup some common functions and load the data.\n",
    "You can skip it for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "IPython version: 5.1.0\n",
      "statsmodels: 0.6.1\n",
      "numpy: 1.11.2\n",
      "scipy: 0.18.1\n",
      "sklearn: 0.18.1\n",
      "pandas: 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bdranalytics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sc\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import sklearn\n",
    "from sklearn import linear_model, model_selection # in old versions use cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.metrics.scorer import r2_scorer, mean_squared_error_scorer\n",
    "import statsmodels\n",
    "from statsmodels.tsa.api import VAR\n",
    "from bdranalytics.model_selection.growingwindow import GrowingWindow\n",
    "from IPython.display import display\n",
    "import IPython\n",
    "print \"IPython version: {}\".format(IPython.__version__)\n",
    "print \"statsmodels: {}\".format(statsmodels.__version__)\n",
    "print \"numpy: {}\".format(np.__version__)\n",
    "print \"scipy: {}\".format(sc.__version__)\n",
    "print \"sklearn: {}\".format(sklearn.__version__)\n",
    "print \"pandas: {}\".format(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_orig = pd.read_csv(os.path.join(datafolder, \"soi.dat\"), header=0, names=[\"soi\"])\n",
    "rng=pd.date_range('1/1/1866', periods=X_orig.size, freq='MS')\n",
    "X_orig = X_orig.set_index(rng)\n",
    "y_orig = pd.read_csv(os.path.join(datafolder, \"recruit.dat\"), header=0, names=[\"recruit\"]).set_index(rng).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some data details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 1)\n",
      "(452,)\n",
      "                       soi  recruit\n",
      "1866-01-01 00:00:00  0.246    68.63\n",
      "1866-02-01 00:00:00  0.311    68.63\n",
      "1866-03-01 00:00:00  0.104    68.63\n",
      "1866-04-01 00:00:00 -0.016    68.63\n",
      "1866-05-01 00:00:00  0.235    68.63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soi</th>\n",
       "      <th>recruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.079381</td>\n",
       "      <td>62.248695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.382915</td>\n",
       "      <td>28.006504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.182750</td>\n",
       "      <td>39.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.115000</td>\n",
       "      <td>68.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.366000</td>\n",
       "      <td>86.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              soi     recruit\n",
       "count  452.000000  452.000000\n",
       "mean     0.079381   62.248695\n",
       "std      0.382915   28.006504\n",
       "min     -1.000000    1.720000\n",
       "25%     -0.182750   39.597500\n",
       "50%      0.115000   68.625000\n",
       "75%      0.366000   86.860000\n",
       "max      1.000000  100.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_orig.shape\n",
    "print y_orig.shape\n",
    "print X_orig.join(y_orig).head()\n",
    "X_orig.join(y_orig).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1A : Creating features\n",
    "Now we have 'X_orig' and 'y_orig', please create a new X dataframe, and y series.\n",
    "The X dataframe should contain all features used to predict, while the y series should be the target variable.\n",
    "If you use a lagged y to predict y, please use at least lag 1.\n",
    "\n",
    "Documentation details:\n",
    "\n",
    "  * http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shift.html\n",
    "  * http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soi_window2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1866-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-02-01 00:00:00</th>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-03-01 00:00:00</th>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-04-01 00:00:00</th>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-05-01 00:00:00</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     soi_window2\n",
       "1866-01-01 00:00:00          NaN\n",
       "1866-02-01 00:00:00        0.311\n",
       "1866-03-01 00:00:00        0.311\n",
       "1866-04-01 00:00:00        0.104\n",
       "1866-05-01 00:00:00        0.235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recruit_lag2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1866-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-02-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-03-01 00:00:00</th>\n",
       "      <td>68.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-04-01 00:00:00</th>\n",
       "      <td>68.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866-05-01 00:00:00</th>\n",
       "      <td>68.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     recruit_lag2\n",
       "1866-01-01 00:00:00           NaN\n",
       "1866-02-01 00:00:00           NaN\n",
       "1866-03-01 00:00:00         68.63\n",
       "1866-04-01 00:00:00         68.63\n",
       "1866-05-01 00:00:00         68.63"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "global name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2f521609f700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mPdWindowTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         PdLagTransformer(2)]\n\u001b[0;32m----> 8\u001b[0;31m                     ).fit_transform(X_orig).head())\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPdFeatureChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPdWindowTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPdLagTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gerben/Projects/bdr-analytics-py/bdranalytics/pandaspipeline/transformers.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gerben/Projects/bdr-analytics-py/bdranalytics/pandaspipeline/transformers.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPdFeatureUnion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from bdranalytics.pandaspipeline.transformers import PdFeatureChain, PdFeatureUnion, PdWindowTransformer, PdLagTransformer\n",
    "\n",
    "display(PdWindowTransformer(2, lambda x:x.max()).fit_transform(X_orig).head())\n",
    "display(PdLagTransformer(2).fit_transform(y_orig.to_frame()).head())\n",
    "display(PdFeatureUnion([\n",
    "        PdWindowTransformer(2, lambda x:x.max()),\n",
    "        PdLagTransformer(2)]\n",
    "                    ).fit_transform(X_orig).head())\n",
    "display(PdFeatureChain([PdWindowTransformer(2, lambda x:x.max()), PdLagTransformer(2)]).fit_transform(X_orig).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_transformers = PdFeatureUnion([PdWindowTransformer(window, lambda x: x.mean()) for window in range(1,12)])\n",
    "lag_transformers = PdFeatureUnion([PdLagTransformer(lag) for lag in range(20)])\n",
    "combined_features = PdFeatureChain([\n",
    "        window_transformers,\n",
    "        lag_transformers\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X_orig,  # the original features\n",
    "               PdLagTransformer(1).fit_transform(y_orig.to_frame()) # the target to predict, lagged by 1\n",
    "              ], axis=1, join_axes=[X_orig.index])\n",
    "X = combined_features.fit_transform(X).dropna() # then wide range of possible windows & lags for all\n",
    "y = y_orig[X.index] # because of dropped rows in X, need to also select corresponding remaining rows from y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "With a dataset of features (X), and a target variable (y), let's see how well we can predict the recruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_score = mean_squared_error\n",
    "model_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "def cross_val(estimator, X, y, scorer = model_scorer, cv_count=10):\n",
    "    return model_selection.cross_val_score(pipeline, X, y.to_frame(), \n",
    "                                           scoring = scorer,\n",
    "                                           cv=GrowingWindow(cv_count))\n",
    "\n",
    "def cross_val_train(estimator, X, y, scorer = model_scorer, cv_count=10):\n",
    "    return [scorer(estimator.fit(X.iloc[train,:], y.iloc[train]),\n",
    "                   X.iloc[train,:],\n",
    "                   y.iloc[train])\n",
    "             for train, test in GrowingWindow(cv_count).split(X)]\n",
    "\n",
    "# if you don't have model_selection use the following:\n",
    "def cross_val_for_old(estimator, X, y, scorer = model_scorer, cv_count=10):\n",
    "    return [scorer(estimator.fit(X.iloc[train,:], y.iloc[train]),\n",
    "                   X.iloc[test,:],\n",
    "                   y.iloc[test])\n",
    "             for train, test in GrowingWindow(cv_count).split(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract a train & test set from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_train, i_test = list(itertools.islice(GrowingWindow(10).split(X), 8, 9))[0]\n",
    "X_train = X.iloc[i_train,:]\n",
    "y_train = y[i_train]\n",
    "\n",
    "X_test = X.iloc[i_test,:]\n",
    "y_test = y[i_test]\n",
    "print \"Train datasize = {}, Test datasets = {} \".format(X_train.shape, X_test.shape)\n",
    "i_subtrain, i_subtest = list(itertools.islice(GrowingWindow(10).split(X_train), 8, 9))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(X_train.columns)\n",
    "display(y_train.head())\n",
    "display(X_train.iloc[:,0:2].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_regression = linear_model.LinearRegression()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        (\"lm\", linear_regression)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, predicting y with the original features (just the soi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"train:\\t{}\".format(np.mean(cross_val_train(pipeline, X_orig, y_orig, cv_count=10)))\n",
    "print \"test:\\t{}\".format(np.mean(cross_val(pipeline, X_orig, y_orig, cv_count=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quality of your model:\n",
    "\n",
    "Probably you do much better with your new set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"train:\\t{}\".format(np.mean(cross_val_train(pipeline, X, y, cv_count=10)))\n",
    "print \"test:\\t{}\".format(np.mean(cross_val(pipeline, X, y, cv_count=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1B: Choosing a different model\n",
    "Feel free to select a different model, and see if you can increase the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_ridge = Pipeline([\n",
    "        (\"ridge\", Ridge(alpha=1.0))\n",
    "    ])\n",
    "print \"train:\\t{}\".format(np.mean(cross_val_train(pipeline_ridge, X, y, cv_count=10)))\n",
    "print \"test:\\t{}\".format(np.mean(cross_val(pipeline_ridge, X, y, cv_count=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid={'alpha':np.power(2.0,range(-2,2))}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_cv = GridSearchCV(estimator = Ridge(),\n",
    "                       param_grid=param_grid,\n",
    "                       scoring=model_scorer,\n",
    "                       n_jobs=1,\n",
    "                       cv=GrowingWindow(10),\n",
    "                       verbose=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"train:\\t{}\".format(np.mean(cross_val_train(ridge_cv.best_estimator_, X, y, cv_count=10)))\n",
    "print \"test:\\t{}\".format(np.mean(cross_val(ridge_cv.best_estimator_, X, y, cv_count=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid={'alpha':np.power(2.0,range(-2,2)),\n",
    "           'l1_ratio':[0.25,0.5,0.75]}\n",
    "print param_grid\n",
    "enet_cv = GridSearchCV(estimator = ElasticNet(),\n",
    "                       param_grid=param_grid,\n",
    "                       scoring=model_scorer,\n",
    "                       n_jobs=1,\n",
    "                       cv=GrowingWindow(10),\n",
    "                       verbose=1).fit(X_train, y_train)\n",
    "print enet_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"train:\\t{}\".format(np.mean(cross_val_train(enet_cv.best_estimator_, X, y, cv_count=10)))\n",
    "print \"test:\\t{}\".format(np.mean(cross_val(enet_cv.best_estimator_, X, y, cv_count=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Selecting features\n",
    "\n",
    "Now try to select a subset of features, which results in a better results.\n",
    "\n",
    "You can do it either manually (comparing coefficients / influences), or use feedback of RFE:  \n",
    "  * http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lm model, it's possible to get the coefficients as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pd.Series(pipeline.fit(X_train, y_train).named_steps['lm'].coef_, X_train.columns).sort_values(ascending=False).head(5)\n",
    "print pd.Series(pipeline.fit(X_train, y_train).named_steps['lm'].coef_, X_train.columns).sort_values(ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the correlation coefficients from a VAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_model = VAR(X_orig.join(y_orig))\n",
    "var_results = var_model.fit(6)\n",
    "var_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_results.plot_acorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfe = RFE(Ridge(alpha=1.0), step=5, n_features_to_select = 1)\n",
    "np.mean(cross_val(rfe, X_train, y_train, cv_count=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfe_fit = RFE(Ridge(alpha=1.0), step=5, n_features_to_select = 1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,rfe_fit.ranking_<=2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfe_all = [np.mean(cross_val(\n",
    "                                Ridge(alpha=1.0), \n",
    "                                X_train.loc[:,rfe_fit.ranking_<=i], \n",
    "                                y_train, \n",
    "                                cv_count=10))\n",
    "     for i in range(1, max(rfe_fit.ranking_))]\n",
    "best_index = np.array(rfe_all).argsort()[::-1][:1]\n",
    "print 'Best nr of features = {}'.format(sum(rfe_fit.ranking_<=(best_index+1)))\n",
    "print 'Which gives score   = {}'.format(rfe_all[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final score\n",
    "Choose your best pipeline and test its performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sub = X_train.loc[:, rfe_fit.ranking_<=(best_index+1)]\n",
    "fit = Ridge(alpha=1.0).fit(X_sub, y_train)\n",
    "test_predictions = fit.predict(X_test.loc[:, rfe_fit.ranking_ <= (best_index+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-model_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bdranalytics]",
   "language": "python",
   "name": "conda-env-bdranalytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
